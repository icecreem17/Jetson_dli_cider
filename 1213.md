```
def ask_openai(llm_model, messages, user_message, functions = ''):
    client = OpenAI()
    proc_messages = messages

    if user_message != '':
        proc_messages.append({"role": "user", "content": user_message})

    if functions == '':
        response = client.chat.completions.create(model=llm_model, messages=proc_messages, temperature = 1.0)
    else:
        response = client.chat.completions.create(model=llm_model, messages=proc_messages, tools=functions, tool_choice="auto") # 이전 코드와 바뀐 부분

    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls

    if tool_calls:
        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors

        available_functions = {
            "measure_co2": measure_co2
        }

        messages.append(response_message)  # extend conversation with assistant's reply

        # Step 4: send the info for each function call and function response to GPT
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)


            print(function_args)

            if 'user_prompt' in function_args:
                function_response = function_to_call(function_args.get('user_prompt'))
            else:
                function_response = function_to_call(**function_args)

            proc_messages.append(
                {
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                }
            )  # extend conversation with function response
        second_response = client.chat.completions.create(
            model=llm_model,
            messages=messages,
        )  # get a new response from GPT where it can see the function response

        assistant_message = second_response.choices[0].message.content
    else:
        assistant_message = response_message.content

    text = assistant_message.replace('\n', ' ').replace(' .', '.').strip()


    proc_messages.append({"role": "assistant", "content": assistant_message})

    return proc_messages, text
```


```
import gradio as gr
import random


messages = []

def process(user_message, chat_history):

    # def ask_openai(llm_model, messages, user_message, functions = ''):
    proc_messages, ai_message = ask_openai("gpt-4o-mini", messages, user_message, functions= use_functions)

    chat_history.append((user_message, ai_message))
    return "", chat_history

with gr.Blocks() as demo:
    chatbot = gr.Chatbot(label="채팅창")
    user_textbox = gr.Textbox(label="입력")
    user_textbox.submit(process, [user_textbox, chatbot], [user_textbox, chatbot])

demo.launch(share=True, debug=True)
```



```
use_functions = [
    {
        "type": "function",
        "function": {
            "name": "measure_co2",
            "description": "Reads CO2 concentration from a CM1106 sensor connected via serial port and returns the measured value in ppm."
        }
    }
]
```

```

use_functions = [
    {
        "type": "function",
        "function": {
            "name": "measure_co2",
            "description": "Reads CO2 concentration from a CM1106 sensor connected via serial port and returns the measured value in ppm.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "gpt_analysis",
            "description": "Analyzes CO2 data and determines air quality and ventilation requirements.",
            "parameters": {
                "type": "object",
                "properties": {
                    "co2_concentration": {
                        "type": "integer",
                        "description": "The measured CO2 concentration in ppm."
                    }
                },
                "required": ["co2_concentration"]
            }
        }
    }
]
```

```
    1. Analyze the air quality.
        2. Determine if ventilation is necessary.
        3. Provide actionable advice for improving air quality if needed.
        4. Explain the health impact of the current CO2 level.
        5. Summarize your response in a way that is understandable to the general public.

```

```
try:
            client = OpenAI()
            response = client.completions.create(
                model="text-davinci-003",
                prompt=prompt,
                max_tokens=300,
                temperature=0.7
            )
            return response["choices"][0]["text"].strip()
        except Exception as e:
            return f"Error during GPT analysis: {e}"
    else:
        return f"Error in measurement: {co2_concentration}"
```

```
# GPT 분석 함수
def gpt_analysis(co2_concentration):
    """
    GPT를 사용하여 CO2 농도를 분석하고 권고 사항을 생성합니다.
    """
    if isinstance(co2_concentration, int):
        prompt = f"""
        The current CO2 concentration is {co2_concentration} ppm.
        Based on this value:
        - Analyze the air quality.
        - Determine if ventilation is necessary.
        - Provide actionable advice for improving air quality.
        """
        try:
            response = openai.Completion.create(
                model="text-davinci-003",
                prompt=prompt,
                max_tokens=300,
                temperature=0.7
            )
            return response["choices"][0]["text"].strip()
        except Exception as e:
            return f"Error during GPT analysis: {e}"
    else:
        return f"Error in measurement: {co2_concentration}"

# Gradio 챗봇 처리 함수
def process_input(user_message):
    """
    사용자 입력을 처리하고 GPT와 연동하여 응답을 생성합니다.
    """
    if "이산화탄소 농도를 알려줘" in user_message:
        # CO2 농도 측정
        co2_value = measure_co2()
        if isinstance(co2_value, int):
            # GPT를 사용하여 분석 및 권고 생성
            gpt_response = gpt_analysis(co2_value)
            return f"현재 이산화탄소 농도는 {co2_value} ppm입니다.\n\n{gpt_response}"
        else:
            return f"Error: {co2_value}"  # 측정 실패 시 에러 메시지 반환
    else:
        return "죄송합니다. 현재 이 질문에 대한 답변을 준비 중입니다."

# Gradio 인터페이스 생성
with gr.Blocks() as demo:
    gr.Markdown("# CO2 Ventilation Assistant")
    chatbot = gr.Chatbot(label="AI Chatbot for CO2 Analysis")
    user_textbox = gr.Textbox(label="Enter your message", placeholder="예: 이산화탄소 농도를 알려줘")
    user_textbox.submit(process_input, inputs=user_textbox, outputs=chatbot)

demo.launch(share=True, debug=True)

```
