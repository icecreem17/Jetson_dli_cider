```
def ask_openai(llm_model, messages, user_message, functions = ''):
    client = OpenAI()
    proc_messages = messages

    if user_message != '':
        proc_messages.append({"role": "user", "content": user_message})

    if functions == '':
        response = client.chat.completions.create(model=llm_model, messages=proc_messages, temperature = 1.0)
    else:
        response = client.chat.completions.create(model=llm_model, messages=proc_messages, tools=functions, tool_choice="auto") # 이전 코드와 바뀐 부분

    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls

    if tool_calls:
        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors

        available_functions = {
            "measure_co2": measure_co2
        }

        messages.append(response_message)  # extend conversation with assistant's reply

        # Step 4: send the info for each function call and function response to GPT
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)


            print(function_args)

            if 'user_prompt' in function_args:
                function_response = function_to_call(function_args.get('user_prompt'))
            else:
                function_response = function_to_call(**function_args)

            proc_messages.append(
                {
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response,
                }
            )  # extend conversation with function response
        second_response = client.chat.completions.create(
            model=llm_model,
            messages=messages,
        )  # get a new response from GPT where it can see the function response

        assistant_message = second_response.choices[0].message.content
    else:
        assistant_message = response_message.content

    text = assistant_message.replace('\n', ' ').replace(' .', '.').strip()


    proc_messages.append({"role": "assistant", "content": assistant_message})

    return proc_messages, text
```


```
import gradio as gr
import random


messages = []

def process(user_message, chat_history):

    # def ask_openai(llm_model, messages, user_message, functions = ''):
    proc_messages, ai_message = ask_openai("gpt-4o-mini", messages, user_message, functions= use_functions)

    chat_history.append((user_message, ai_message))
    return "", chat_history

with gr.Blocks() as demo:
    chatbot = gr.Chatbot(label="채팅창")
    user_textbox = gr.Textbox(label="입력")
    user_textbox.submit(process, [user_textbox, chatbot], [user_textbox, chatbot])

demo.launch(share=True, debug=True)
```



```
use_functions = [
    {
        "type": "function",
        "function": {
            "name": "measure_co2",
            "description": "Reads CO2 concentration from a CM1106 sensor connected via serial port and returns the measured value in ppm."
        }
    }
]
```

```

use_functions = [
    {
        "type": "function",
        "function": {
            "name": "measure_co2",
            "description": "Reads CO2 concentration from a CM1106 sensor connected via serial port and returns the measured value in ppm.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "gpt_analysis",
            "description": "Analyzes CO2 data and determines air quality and ventilation requirements.",
            "parameters": {
                "type": "object",
                "properties": {
                    "co2_concentration": {
                        "type": "integer",
                        "description": "The measured CO2 concentration in ppm."
                    }
                },
                "required": ["co2_concentration"]
            }
        }
    }
]
```

```
    1. Analyze the air quality.
        2. Determine if ventilation is necessary.
        3. Provide actionable advice for improving air quality if needed.
        4. Explain the health impact of the current CO2 level.
        5. Summarize your response in a way that is understandable to the general public.

```

```
try:
            client = OpenAI()
            response = client.completions.create(
                model="text-davinci-003",
                prompt=prompt,
                max_tokens=300,
                temperature=0.7
            )
            return response["choices"][0]["text"].strip()
        except Exception as e:
            return f"Error during GPT analysis: {e}"
    else:
        return f"Error in measurement: {co2_concentration}"
```

```
# GPT 분석 함수
def gpt_analysis(co2_concentration):
    """
    GPT를 사용하여 CO2 농도를 분석하고 권고 사항을 생성합니다.
    """
    if isinstance(co2_concentration, int):
        prompt = f"""
        The current CO2 concentration is {co2_concentration} ppm.
        Based on this value:
        - Analyze the air quality.
        - Determine if ventilation is necessary.
        - Provide actionable advice for improving air quality.
        """
        try:
            response = openai.Completion.create(
                model="text-davinci-003",
                prompt=prompt,
                max_tokens=300,
                temperature=0.7
            )
            return response["choices"][0]["text"].strip()
        except Exception as e:
            return f"Error during GPT analysis: {e}"
    else:
        return f"Error in measurement: {co2_concentration}"

# Gradio 챗봇 처리 함수
def process_input(user_message):
    """
    사용자 입력을 처리하고 GPT와 연동하여 응답을 생성합니다.
    """
    if "이산화탄소 농도를 알려줘" in user_message:
        # CO2 농도 측정
        co2_value = measure_co2()
        if isinstance(co2_value, int):
            # GPT를 사용하여 분석 및 권고 생성
            gpt_response = gpt_analysis(co2_value)
            return f"현재 이산화탄소 농도는 {co2_value} ppm입니다.\n\n{gpt_response}"
        else:
            return f"Error: {co2_value}"  # 측정 실패 시 에러 메시지 반환
    else:
        return "죄송합니다. 현재 이 질문에 대한 답변을 준비 중입니다."

# Gradio 인터페이스 생성
with gr.Blocks() as demo:
    gr.Markdown("# CO2 Ventilation Assistant")
    chatbot = gr.Chatbot(label="AI Chatbot for CO2 Analysis")
    user_textbox = gr.Textbox(label="Enter your message", placeholder="예: 이산화탄소 농도를 알려줘")
    user_textbox.submit(process_input, inputs=user_textbox, outputs=chatbot)

demo.launch(share=True, debug=True)

```

```
import Jetson.GPIO as GPIO
import time
import math
import serial
import time

def measure_co2():
    SERIAL_PORT = "/dev/ttyUSB0"  # 실제 연결된 포트로 변경
    BAUD_RATE = 9600

    try:
        with serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=5) as ser:
            ser.write(b'\x11\x01\x01\xED')  # CM1106 센서 명령어
            time.sleep(5)  # 응답 대기 시간

            # 응답 데이터 읽기
            response = ser.read_all()  # 가능한 모든 데이터 읽기
            print(f"Raw response (bytes): {response}")

            try:
                response = response.decode('ascii')  # 디코딩 시도
                print(f"Decoded response: {response}")
            except Exception as decode_error:
                print(f"Decoding error: {decode_error}")
                return "Error: Failed to decode response."

            if response.startswith("CO2:"):
                co2_value = response.split(":")[1].strip()
                return co2_value
            else:
                print("Error: Unexpected response format.")
                return "Error: Unexpected response format."

    except serial.SerialException as e:
        print(f"Serial connection error: {e}")
        return "Error: Serial connection issue."

    except Exception as e:
        print(f"Error during measurement: {e}")
        return f"Error: {e}"
```
수정
```
import serial
import time

def measure_co2():
    SERIAL_PORT = "/dev/ttyUSB0"  # 실제 연결된 포트로 변경
    BAUD_RATE = 9600

    try:
        with serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=5) as ser:
            ser.write(b'\x11\x01\x01\xED')  # CM1106 센서 명령어
            time.sleep(5)  # 응답 대기 시간

            # 응답 데이터 읽기
            response = ser.read_all()  # 가능한 모든 데이터 읽기
            print(f"Raw response (bytes): {response}")  # 디버깅용

            try:
                response = response.decode('ascii')  # 디코딩 시도
                print(f"Decoded response: {response}")  # 디버깅용
            except Exception as decode_error:
                return f"Error: Failed to decode response ({decode_error})"

            if response.startswith("CO2:"):
                co2_value = response.split(":")[1].strip()
                return int(co2_value)  # CO2 농도 반환
            else:
                return "Error: Unexpected response format."

    except serial.SerialException as e:
        return f"Error: Serial connection issue ({e})"

    except Exception as e:
        return f"Error: {e}"
```

```

네, 맞습니다! Agent와 Task를 정의하고, 이를 Crew(에이전트 그룹)로 구성하는 방식은 에이전트 기반 시스템에서 더욱 구조적이고 명확한 워크플로를 구현할 수 있는 방법입니다. 아래는 Agent, Task, 그리고 이를 합쳐 Crew로 구성한 예제 코드입니다.

에이전트-태스크-Crew 설계 코드
python
코드 복사
# 필요한 모듈 임포트
import openai
import serial
import time
import gradio as gr

# OpenAI API 키 설정
openai.api_key = "sk-프로젝트에 사용된 API 키"

# **Agent 정의**
class Agent:
    def __init__(self, role, goal, function, tools=None, memory=True):
        self.role = role
        self.goal = goal
        self.function = function
        self.tools = tools or []
        self.memory = memory

    def execute(self, **kwargs):
        return self.function(**kwargs)


# **Task 정의**
class Task:
    def __init__(self, description, agent):
        self.description = description
        self.agent = agent

    def run(self, **kwargs):
        print(f"Executing Task: {self.description}")
        return self.agent.execute(**kwargs)
```
```
measure_co2_agent = Agent(
    role="Sensor",
    goal="현재 이산화탄소 농도를 측정합니다.",
    function=measure_co2,
)
```
```
gpt_analysis_agent = Agent(
    role="Analyzer",
    goal="CO2 농도를 기반으로 GPT 모델을 사용해 실내 공기질을 분석하고 권고를 생성합니다.",
    function=lambda co2_value: gpt_analysis(co2_value),
)
```
```
# **Task 정의**
co2_measure_task = Task(
    description="CO2 농도를 측정합니다.",
    agent=measure_co2_agent,
)

gpt_analysis_task = Task(
    description="측정된 CO2 농도를 기반으로 분석 결과를 생성합니다.",
    agent=gpt_analysis_agent,
)

# **Crew 정의**
class Crew:
    def __init__(self, tasks):
        self.tasks = tasks

    def run(self):
        context = {}
        for task in self.tasks:
            result = task.run(**context)
            if "error" in result:
                return result["error"]
            context.update(result)
        return context

# Crew 생성
co2_analysis_crew = Crew(tasks=[co2_measure_task, gpt_analysis_task])
```
```
# **Gradio를 통한 인터페이스**
def process_input(user_message):
    if "이산화탄소 농도를 알려줘" in user_message:
        result = co2_analysis_crew.run()
        if "error" in result:
            return f"Error: {result}"
        else:
            co2_value = result["co2_value"]
            analysis = result["analysis"]
            return f"현재 이산화탄소 농도는 {co2_value} ppm입니다.\n\n{analysis}"
    else:
        return "죄송합니다. 현재 이 질문에 대한 답변을 준비 중입니다."

def chatbot_interface():
    with gr.Blocks() as demo:
        gr.Markdown("# CO2 Ventilation Assistant")
        chatbot = gr.Chatbot(label="AI Chatbot for CO2 Analysis")
        user_textbox = gr.Textbox(label="Enter your message", placeholder="예: 이산화탄소 농도를 알려줘")
        user_textbox.submit(process_input, inputs=user_textbox, outputs=chatbot)
    demo.launch(share=True, debug=True)

# 프로그램 실행
if __name__ == "__main__":
    chatbot_interface()
```
```
# 새로 추가함

def chatbot_interface():
    """
    Gradio chatbot interface that integrates CO2 measurement and GPT-based analysis.
    """
    # def process_input(_):
    #     co2_concentration = measure_co2()  # CO2 농도 측정
    #     gpt_response = gpt_analysis(co2_concentration)  # GPT 분석 호출
    #     return gpt_response

    # Gradio 챗봇 처리 함수
    def process_input(user_message):
        """
        사용자 입력을 처리하고 GPT와 연동하여 응답을 생성합니다.
        """
        if "이산화탄소 농도를 알려줘" in user_message:
            # CO2 농도 측정
            co2_value = measure_co2()
            if isinstance(co2_value, int):
                # GPT를 사용하여 분석 및 권고 생성
                gpt_response = gpt_analysis(co2_value)
                return f"현재 이산화탄소 농도는 {co2_value} ppm입니다.\n\n{gpt_response}"
            else:
                return f"Error: {co2_value}"  # 측정 실패 시 에러 메시지 반환
        else:
            return "죄송합니다. 현재 이 질문에 대한 답변을 준비 중입니다."

    with gr.Blocks() as demo:
        gr.Markdown("# CO2 Ventilation Assistant (GPT-Based)")
        chatbot = gr.Chatbot(label="AI Chatbot for CO2 Ventilation Advice")
        user_textbox = gr.Textbox(label="Press Enter to Measure CO2 and Get Advice")
        user_textbox.submit(process_input, None, chatbot)

    demo.launch(share=True, debug=True)
```
